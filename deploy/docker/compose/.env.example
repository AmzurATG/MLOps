# ============================================================================
# MLOps/CVOps Platform Environment Configuration
# ============================================================================

# ----------------------------------------------------------------------------
# TRINO CATALOG (Branch Switching)
# ----------------------------------------------------------------------------
# Set this to switch ALL downstream tables to a different branch
# Use ./scripts/branch_manager.sh to create feature branches
#
# Available catalogs:
#   iceberg_dev          - Development branch (default)
#   iceberg_main         - Production/main branch
#   iceberg_experiment_* - Feature branches (created by branch_manager.sh)
#
TRINO_CATALOG=iceberg_dev

# ----------------------------------------------------------------------------
# LAKEFS (Data Versioning)
# ----------------------------------------------------------------------------
# Generate new keys via LakeFS UI or API after initial setup
LAKEFS_ACCESS_KEY_ID=YOUR_LAKEFS_ACCESS_KEY_HERE
LAKEFS_SECRET_ACCESS_KEY=YOUR_LAKEFS_SECRET_KEY_HERE
LAKEFS_WEBHOOK_SECRET=your_webhook_secret_here

# ----------------------------------------------------------------------------
# MINIO (Object Storage)
# ----------------------------------------------------------------------------
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=password123

# ----------------------------------------------------------------------------
# DAGSTER (Orchestration)
# ----------------------------------------------------------------------------
DAGSTER_POSTGRES_PASSWORD=dagster

# ----------------------------------------------------------------------------
# LABEL STUDIO (Data Labeling)
# ----------------------------------------------------------------------------
LABELSTUDIO_USERNAME=admin@example.com
LABELSTUDIO_PASSWORD=admin123
LABELSTUDIO_API_TOKEN=key
LABELSTUDIO_PROJECT_ID=1
LABELSTUDIO_EXPORT_BATCH_SIZE=12000
LABELSTUDIO_MAX_IN_REVIEW=12000
LABELSTUDIO_MERGE_BATCH_SIZE=12000

# ----------------------------------------------------------------------------
# AIRBYTE (Data Ingestion) - Optional
# ----------------------------------------------------------------------------
AIRBYTE_SERVER_URL=http://host.docker.internal:18001
AIRBYTE_CLIENT_ID=98228cf6-5e7a-4ee7-9a80-ebd657830526
AIRBYTE_CLIENT_SECRET=kRVLPgCjNi7nSiPGeaRaCue7KF8HICQq
AIRBYTE_WORKSPACE_ID=3591ce40-a49a-4336-a576-1c5793104156
AIRBYTE_CONNECTION_ID=45f50004-08c3-4051-8435-aafc827b5bb5

# ----------------------------------------------------------------------------
# LAKEHOUSE CONFIGURATION
# ----------------------------------------------------------------------------
LAKEHOUSE_BRONZE_REPO=bronze
LAKEHOUSE_WAREHOUSE_REPO=warehouse
LAKEHOUSE_DEV_BRANCH=dev
LAKEHOUSE_MAIN_BRANCH=main

# ----------------------------------------------------------------------------
# NESSIE (Iceberg Catalog Branches)
# ----------------------------------------------------------------------------
# Branch for iceberg_experiment catalog (used for feature branches/experiments)
NESSIE_EXPERIMENT_BRANCH=experiment-v1

# ----------------------------------------------------------------------------
# SENSORS (Dagster)
# ----------------------------------------------------------------------------
SENSOR_EXPORT_INTERVAL_SECONDS=300
SENSOR_MERGE_INTERVAL_SECONDS=300

# ----------------------------------------------------------------------------
# CVOPS (Computer Vision)
# ----------------------------------------------------------------------------
CVOPS_REPO=cv-data
CVOPS_BRANCH=dev
CVOPS_WEBHOOK_SECRET=
CVOPS_VERIFY_WEBHOOK=false
YOLO_DEVICE=cpu
YOLO_DUMMY_MODE=true
YOLO_CONFIDENCE=0.25
YOLO_MODEL_PATH=yolov8n.pt
CVOPS_MLFLOW_EXPERIMENT=cvops_object_detection

# ----------------------------------------------------------------------------
# JUPYTER
# ----------------------------------------------------------------------------
JUPYTER_TOKEN=jupyter
JUPYTER_AUTO_MODE=true
JUPYTER_NOTEBOOK_PATH=/app/notebooks/01_bronze_to_silver_FIXED.ipynb

# ----------------------------------------------------------------------------
# AUTO-RETRAIN CONFIGURATION (MLOPS_ prefix for Pydantic Settings)
# ----------------------------------------------------------------------------
MLOPS_RETRAIN_ENABLED=true
MLOPS_RETRAIN_DRIFT_THRESHOLD=0.3
MLOPS_RETRAIN_F1_THRESHOLD=0.7
MLOPS_RETRAIN_ACCURACY_THRESHOLD=0.8
MLOPS_RETRAIN_MIN_NEW_LABELS=100
MLOPS_RETRAIN_COOLDOWN_HOURS=24
MLOPS_RETRAIN_SENSOR_INTERVAL_SECONDS=300

# ----------------------------------------------------------------------------
# SHADOW MODE CONFIGURATION (MLOPS_ prefix for Pydantic Settings)
# ----------------------------------------------------------------------------
MLOPS_SHADOW_ENABLED=false
MLOPS_SHADOW_STAGE=Staging
MLOPS_SHADOW_LOG_ALL_PREDICTIONS=true
MLOPS_SHADOW_LOG_DISAGREEMENTS_ONLY=false
MLOPS_SHADOW_AGREEMENT_ALERT_THRESHOLD=0.9
MLOPS_SHADOW_SCORE_DIFF_ALERT_THRESHOLD=0.2

# ----------------------------------------------------------------------------
# PERFORMANCE MONITORING (MLOPS_ prefix for Pydantic Settings)
# ----------------------------------------------------------------------------
MLOPS_PERFORMANCE_F1_THRESHOLD=0.7
MLOPS_PERFORMANCE_ACCURACY_THRESHOLD=0.8
MLOPS_PERFORMANCE_MIN_SAMPLES=50


# ============================================================================
# ADD THESE TO YOUR EXISTING .env FILE
# ============================================================================
# LiteLLM Local Development Configuration
# Copy these lines to the bottom of your .env file
# ============================================================================

# ----------------------------------------------------------------------------
# LITELLM CONFIGURATION
# ----------------------------------------------------------------------------
# Master key for admin access (used to create virtual keys)
LITELLM_MASTER_KEY=sk-local-dev-2025

# Database configuration (separate from your production database)
LITELLM_DB_USER=litellm
LITELLM_DB_PASSWORD=litellm123
LITELLM_DB_NAME=litellm

# Redis configuration for caching
LITELLM_REDIS_PASSWORD=redis123

# UI Login Credentials
LITELLM_UI_USERNAME=admin
LITELLM_UI_PASSWORD=admin123

# Salt key for encrypting API keys stored in database
LITELLM_SALT_KEY=sk-salt-local-dev-2025

# MLflow Integration (connects to your existing MLflow server)
# No changes needed - uses existing MLFLOW_TRACKING_URI if you have it
# Or defaults to http://exp-mlflow:5000
LITELLM_MLFLOW_EXPERIMENT=litellm-local-dev

# ----------------------------------------------------------------------------
# OPENAI API KEY (Required for LiteLLM to work)
# ----------------------------------------------------------------------------
# Add your OpenAI API key here
# Get it from: https://platform.openai.com/api-keys
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
# ----------------------------------------------------------------------------
# GROQ (FREE TIER - Get key from console.groq.com)
# ----------------------------------------------------------------------------
GROQ_API_KEY=YOUR_GROQ_API_KEY_HERE

# OPTIONAL: OTHER LLM PROVIDERS
# ----------------------------------------------------------------------------
# Uncomment and add keys if you want to use other providers

# Anthropic Claude
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# Google Vertex AI
# VERTEX_PROJECT=your-gcp-project
# VERTEX_LOCATION=us-central1

# Azure OpenAI
# AZURE_API_KEY=your-azure-key
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2024-02-01

# ----------------------------------------------------------------------------
# NOTES
# ----------------------------------------------------------------------------
# After adding these variables:
# 1. Restart your docker-compose services
# 2. LiteLLM will be available at http://localhost:4000
# 3. LiteLLM UI will be at http://localhost:4000/ui
# 4. All traces logged to MLflow at http://localhost:15000
# ============================================================================
